# 不算总结的总结

## Spark Core

### DAG

DAG本身是有向无环图的缩写，在Spark Core中用DAGScheduler做Stage的划分。Stage的划分过程（源码）=>



## checkPoint Cache

以下是个人理解：

用好这俩可以提高效率，checkPoint意思就是检查点，或者称之为还原点（类比成系统还原点也不为过），可以将计算步骤中的某一个RDD做检查点，存在磁盘上，这样后面出问题的时候，检查点之前的就不用在计算了，提高了容错性能和效率，又因为是存在磁盘上，所以可以存的比较大。sparkstreaming里面的批次累加（updateStateBykey）需要用到检查点

Cache意思就是缓存，顾名思义就是放在内存里的东西，它可以把RDD缓存起来。放在内存里就意味着读写性能极高，但是同时内存资源比磁盘资源更稀有（就是小的意思），不适合存放太大的。Cache的级别可以调默认只放到内存（Memory Only）

## 分区器

本身是有一个defaultPartitioner,其实就是Hash取余分区，可以自定义分区器，需要实现Partitioner特质



## 累加器

因为RDD是分布式的，分区都不在一块，而且Exectuor的计算结果是没办法返回到Driver端的，因此迭代的算子对共享的变量是累加不了的。这个时候需要累加器

自带的有个LongAccmulate,DoubleAccmulate



## 广播变量

Broadcast,广播变量，用途就是把变量广播出去，发到每一个exectuor里（这个旧版本是一个一个发的，新版本用的torrent技术，就跟你下片一样，P2P的，快很多）。然后每一个task执行的时候就不需要每个都要获取一遍了，直接去Exectuor里面取，不然太浪费网络资源。

RDD不能直接广播，毕竟RDD只是一个引用，懒加载的，必须collect起来在广播。

广播变量的数据不可太大，如果太大，会在Executor占用大量的缓存，相对于计算的时候的缓存就少很多。

？？一般来讲广播一些维度表比较常见？？？我猜的



## 常用文件输入输出总结



集群启动过程

1. 提交任务到master，master启动masterendpoint交互程序，启动onstart方法生成计时器
2. master调用receive不断接受其他服务的请求和结果
3. master搜索slave文件，调用脚本启动worker
4. worker启动workerendpoint，通过onstart方法向所有master进行注册
5. master收到注册信息后判断自己状态，若是standy，直接忽略信息，若是active，接受注册信息并判断worker是否重复注册，若没有，保存新的worker，并返回注册信息结果
6. worker收到注册信息的结果后，启动定时器，进行心跳反馈

任务提交（四个阶段）

1. RDD生成
2. stage划分
3. task生成
4. 任务提交





## Spark SQL

DataFrame/DataSet

- DataFrame是弱类型，是抽象数据集，Rdd和Schema的集合，可以像二维表一样操作

- DataSet：属于DataFrame的父类，DataFrame=Dataset[row]，强类型

RDD到DataFrame的三种方式

UDF

UDAF

开窗函数

外部Hive集成

SparkSQL的输入输出



## Spark Streaming

原语Transformations和Output Operations

经典WC案例

批次累加

窗口

消费KafKa数据



## Spark On Yarn的两种模式

cluster和client