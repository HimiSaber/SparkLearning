# 不算总结的总结

## Spark Core

### DAG

DAG本身是有向无环图的缩写，在Spark Core中用DAGScheduler做Stage的划分。Stage的划分过程（源码）=>



## checkPoint Cache

以下是个人理解：

用好这俩可以提高效率，checkPoint意思就是检查点，或者称之为还原点（类比成系统还原点也不为过），可以将计算步骤中的某一个RDD做检查点，存在磁盘上，这样后面出问题的时候，检查点之前的就不用在计算了，提高了容错性能和效率，又因为是存在磁盘上，所以可以存的比较大。sparkstreaming里面的批次累加（updateStateBykey）需要用到检查点

Cache意思就是缓存，顾名思义就是放在内存里的东西，它可以把RDD缓存起来。放在内存里就意味着读写性能极高，但是同时内存资源比磁盘资源更稀有（就是小的意思），不适合存放太大的。Cache的级别可以调默认只放到内存（Memory Only）

## 分区器

本身是有一个defaultPartitioner,其实就是Hash取余分区，可以自定义分区器，需要实现Partitioner特质



## 累加器

因为RDD是分布式的，分区都不在一块，而且Exectuor的计算结果是没办法返回到Driver端的，因此迭代的算子对共享的变量是累加不了的。这个时候需要累加器

自带的有个LongAccmulate,DoubleAccmulate



## 广播变量

Broadcast,广播变量，用途就是把变量广播出去，发到每一个exectuor里（这个旧版本是一个一个发的，新版本用的torrent技术，就跟你下片一样，P2P的，快很多）。然后每一个task执行的时候就不需要每个都要获取一遍了，直接去Exectuor里面取，不然太浪费网络资源。

RDD不能直接广播，毕竟RDD只是一个引用，懒加载的，必须collect起来在广播。

？？一般来讲广播一些维度表比较常见？？？我猜的



## 常用文件输入输出总结



集群启动过程

任务提交（四个阶段）







## Spark SQL

DataFrame/DataSet

RDD到DataFrame的三种方式

UDF

UDAF

开窗函数

外部Hive集成

SparkSQL的输入输出



## Spark Streaming

原语Transformations和Output Operations

经典WC案例

批次累加

窗口

消费KafKa数据



## Spark On Yarn的两种模式

cluster和client